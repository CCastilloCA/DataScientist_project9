{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # PROYECTO SPRINT 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OBJETIVO DEL PROYECTO\n",
    "<p>\n",
    "En Beta Bank, los clientes están abandonando gradualmente el banco cada mes. Este fenómeno es costoso, ya que los banqueros han descubierto que es más económico retener a los clientes existentes que adquirir nuevos. El objetivo principal de este proyecto es predecir si un cliente abandonará el banco pronto, utilizando datos históricos sobre el comportamiento de los clientes y la terminación de contratos con el banco.</P>\n",
    "\n",
    "<P>Resultados Esperados:</P>\n",
    "<P>\n",
    "Se espera desarrollar un modelo predictivo con un alto valor F1-score, que indique su capacidad para predecir con precisión el abandono de clientes. Se establece un objetivo mínimo de un valor F1 de 0.59.</P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Descarga y prepara los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar archivo DataFrame\n",
    "df = pd.read_csv('Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0        2.0       0.00              1          1               1   \n",
       "1        1.0   83807.86              1          0               1   \n",
       "2        8.0  159660.80              3          1               0   \n",
       "3        1.0       0.00              2          0               0   \n",
       "4        2.0  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995     5.0       0.00              2          1               0   \n",
       "9996    10.0   57369.61              1          1               1   \n",
       "9997     7.0       0.00              1          0               1   \n",
       "9998     3.0   75075.31              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.000000e+04</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>9091.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569094e+07</td>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>4.997690</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2886.89568</td>\n",
       "      <td>7.193619e+04</td>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.894723</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.556570e+07</td>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2500.75000</td>\n",
       "      <td>1.562853e+07</td>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5000.50000</td>\n",
       "      <td>1.569074e+07</td>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7500.25000</td>\n",
       "      <td>1.575323e+07</td>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10000.00000</td>\n",
       "      <td>1.581569e+07</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RowNumber    CustomerId   CreditScore           Age       Tenure  \\\n",
       "count  10000.00000  1.000000e+04  10000.000000  10000.000000  9091.000000   \n",
       "mean    5000.50000  1.569094e+07    650.528800     38.921800     4.997690   \n",
       "std     2886.89568  7.193619e+04     96.653299     10.487806     2.894723   \n",
       "min        1.00000  1.556570e+07    350.000000     18.000000     0.000000   \n",
       "25%     2500.75000  1.562853e+07    584.000000     32.000000     2.000000   \n",
       "50%     5000.50000  1.569074e+07    652.000000     37.000000     5.000000   \n",
       "75%     7500.25000  1.575323e+07    718.000000     44.000000     7.000000   \n",
       "max    10000.00000  1.581569e+07    850.000000     92.000000    10.000000   \n",
       "\n",
       "             Balance  NumOfProducts    HasCrCard  IsActiveMember  \\\n",
       "count   10000.000000   10000.000000  10000.00000    10000.000000   \n",
       "mean    76485.889288       1.530200      0.70550        0.515100   \n",
       "std     62397.405202       0.581654      0.45584        0.499797   \n",
       "min         0.000000       1.000000      0.00000        0.000000   \n",
       "25%         0.000000       1.000000      0.00000        0.000000   \n",
       "50%     97198.540000       1.000000      1.00000        1.000000   \n",
       "75%    127644.240000       2.000000      1.00000        1.000000   \n",
       "max    250898.090000       4.000000      1.00000        1.000000   \n",
       "\n",
       "       EstimatedSalary        Exited  \n",
       "count     10000.000000  10000.000000  \n",
       "mean     100090.239881      0.203700  \n",
       "std       57510.492818      0.402769  \n",
       "min          11.580000      0.000000  \n",
       "25%       51002.110000      0.000000  \n",
       "50%      100193.915000      0.000000  \n",
       "75%      149388.247500      0.000000  \n",
       "max      199992.480000      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validamos información estadistica del DataFrame\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           10000 non-null  float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#Remplazamos valores ausentes con la media y evitamos perder información del df\n",
    "mean_tenure = df['Tenure'].mean()\n",
    "df['Tenure'].fillna(mean_tenure,inplace=True)\n",
    "\n",
    "#Verificamos si se completaron los valores ausentes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<P>Remplazamos valores ausentes con la media para no perder ninguna fila y poder continuar el análisis con la mayor cantidad de datos y el análisis siga siendo representativo. </P>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examinar el equilibrio de clases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exited\n",
      "0    7963\n",
      "1    2037\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Identificar la distribución de la variable objetivito 'Exited'\n",
    "class_distribution = df['Exited'].value_counts()\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Entrenar el modelo sin tener en cuenta el desequilibrio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Convertir variables categóricas en variables dummy\n",
    "features_encoded = pd.get_dummies(df, columns=['Geography', 'Gender'])\n",
    "\n",
    "# Dividir los datos en características y variable objetivo\n",
    "features = features_encoded.drop(columns=['Exited','RowNumber','CustomerId','Surname'])\n",
    "target = features_encoded['Exited']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
    "features_train1, features_valid1, target_train1, target_valid1 = train_test_split(features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "# Crear y entrenar el modelo de árbol de decisión\n",
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "model.fit(features_train1, target_train1)\n",
    "predicted_valid = model.predict(features_valid1)\n",
    "\n",
    "print(predicted_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizó la codificacióne One-hot (dummy) porque tenía características categóricas en mis datos y no se puede manejar automáticamente. \n",
    "Para resolver este problema, se reprocesó los datos para manejar las características categóricas y lograr convertirlas en carácterísticas numéricas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Mejora la calidad del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de clasificación en el conjunto de validación (upsampled):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.93      0.91      1609\n",
      "           1       0.66      0.53      0.59       391\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.78      0.73      0.75      2000\n",
      "weighted avg       0.85      0.86      0.85      2000\n",
      "\n",
      "Mejores parámetros (upsampled): {'n_estimators': 180, 'max_depth': None}\n",
      "Puntaje F1 en el conjunto de validación (upsampled): 0.5889046941678521\n",
      "AUC-ROC en el conjunto de validación (upsampled): 0.8442583994443023\n",
      "\n",
      "Reporte de clasificación en el conjunto de validación (downsampled):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.78      0.85      1609\n",
      "           1       0.45      0.73      0.56       391\n",
      "\n",
      "    accuracy                           0.78      2000\n",
      "   macro avg       0.69      0.76      0.70      2000\n",
      "weighted avg       0.83      0.78      0.79      2000\n",
      "\n",
      "Mejores parámetros (downsampled): {'n_estimators': 50, 'max_depth': None}\n",
      "Puntaje F1 en el conjunto de validación (downsampled): 0.560546875\n",
      "AUC-ROC en el conjunto de validación (downsampled): 0.8398172682751593\n",
      "\n",
      "Reporte de clasificación en el conjunto de prueba (upsampled):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90      1573\n",
      "           1       0.68      0.52      0.59       427\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.78      0.73      0.75      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n",
      "Puntaje F1 en el conjunto de prueba (upsampled): 0.58994708994709\n",
      "AUC-ROC en el conjunto de prueba (upsampled): 0.8543126024497112\n",
      "\n",
      "Reporte de clasificación en el conjunto de prueba (downsampled):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.79      0.85      1573\n",
      "           1       0.50      0.75      0.60       427\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.71      0.77      0.73      2000\n",
      "weighted avg       0.83      0.79      0.80      2000\n",
      "\n",
      "Puntaje F1 en el conjunto de prueba (downsampled): 0.6007462686567164\n",
      "AUC-ROC en el conjunto de prueba (downsampled): 0.8530962331260393\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
    "df_train_valid, df_test = train_test_split(features_encoded, test_size=0.2, random_state=12345)\n",
    "df_train, df_valid = train_test_split(df_train_valid, test_size=0.25, random_state=12345)\n",
    "\n",
    "# Extraer características y objetivos para entrenamiento\n",
    "features_train = df_train.drop(columns=['Exited','RowNumber','CustomerId','Surname'])\n",
    "target_train = df_train['Exited']\n",
    "\n",
    "# Extraer características y objetivos para validación\n",
    "features_valid = df_valid.drop(columns=['Exited','RowNumber','CustomerId','Surname'])\n",
    "target_valid = df_valid['Exited']\n",
    "\n",
    "# Extraer características y objetivos para prueba\n",
    "features_test = df_test.drop(columns=['Exited','RowNumber','CustomerId','Surname'])\n",
    "target_test = df_test['Exited']\n",
    "\n",
    "# Combinar características y variable objetivo para el conjunto de entrenamiento\n",
    "train_data = pd.concat([features_train, target_train], axis=1)\n",
    "\n",
    "# Separar muestras por clase\n",
    "class_0 = train_data[train_data['Exited'] == 0]\n",
    "class_1 = train_data[train_data['Exited'] == 1]\n",
    "\n",
    "# Upsample de la clase minoritaria (clase 1)\n",
    "class_1_upsampled = resample(class_1, replace=True, n_samples=len(class_0), random_state=12345)\n",
    "\n",
    "# Downsample de la clase mayoritaria (clase 0)\n",
    "class_0_downsampled = resample(class_0, replace=False, n_samples=len(class_1), random_state=12345)\n",
    "\n",
    "# Combina las muestras de las dos clases luego de upsample y downsample\n",
    "upsampled_train_data = pd.concat([class_0, class_1_upsampled])\n",
    "downsampled_train_data = pd.concat([class_1, class_0_downsampled])\n",
    "\n",
    "# Dividir características y variable objetivo después del remuestreo (upsampled)\n",
    "features_train_upsampled = upsampled_train_data.drop(columns=['Exited'])\n",
    "target_train_upsampled = upsampled_train_data['Exited']\n",
    "\n",
    "# Dividir características y variable objetivo después del remuestreo (downsampled)\n",
    "features_train_downsampled = downsampled_train_data.drop(columns=['Exited'])\n",
    "target_train_downsampled = downsampled_train_data['Exited']\n",
    "\n",
    "# Entrenar varios modelos con diferentes hiperparámetros (upsampled)\n",
    "models_upsampled = []\n",
    "for n_estimators in [50, 120, 180]:\n",
    "    for max_depth in [None, 20, 40]:\n",
    "        rf_classifier = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=12345)\n",
    "        rf_classifier.fit(features_train_upsampled, target_train_upsampled)\n",
    "        models_upsampled.append((rf_classifier, n_estimators, max_depth))\n",
    "\n",
    "# Entrenar varios modelos con diferentes hiperparámetros (downsampled)\n",
    "models_downsampled = []\n",
    "for n_estimators in [50, 120, 180]:\n",
    "    for max_depth in [None, 20, 40]:\n",
    "        rf_classifier = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=12345)\n",
    "        rf_classifier.fit(features_train_downsampled, target_train_downsampled)\n",
    "        models_downsampled.append((rf_classifier, n_estimators, max_depth))\n",
    "\n",
    "# Evaluar modelos en el conjunto de validación y seleccionar el mejor basado en F1-score y AUC-ROC (upsampled)\n",
    "best_model_upsampled = None\n",
    "best_f1_upsampled = 0\n",
    "best_auc_roc_upsampled = 0\n",
    "for model, n_estimators, max_depth in models_upsampled:\n",
    "    target_pred_val = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, target_pred_val)\n",
    "    auc_roc = roc_auc_score(target_valid, model.predict_proba(features_valid)[:, 1])\n",
    "    if f1 > best_f1_upsampled:\n",
    "        best_model_upsampled = model\n",
    "        best_f1_upsampled = f1\n",
    "        best_auc_roc_upsampled = auc_roc\n",
    "        best_params_upsampled = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "\n",
    "# Evaluar modelos en el conjunto de validación y seleccionar el mejor basado en F1-score y AUC-ROC (downsampled)\n",
    "best_model_downsampled = None\n",
    "best_f1_downsampled = 0\n",
    "best_auc_roc_downsampled = 0\n",
    "for model, n_estimators, max_depth in models_downsampled:\n",
    "    target_pred_val = model.predict(features_valid)\n",
    "    f1 = f1_score(target_valid, target_pred_val)\n",
    "    auc_roc = roc_auc_score(target_valid, model.predict_proba(features_valid)[:, 1])\n",
    "    if f1 > best_f1_downsampled:\n",
    "        best_model_downsampled = model\n",
    "        best_f1_downsampled = f1\n",
    "        best_auc_roc_downsampled = auc_roc\n",
    "        best_params_downsampled = {'n_estimators': n_estimators, 'max_depth': max_depth}\n",
    "\n",
    "# Imprimir el reporte de clasificación del mejor modelo en el conjunto de validación (upsampled)\n",
    "print(\"Reporte de clasificación en el conjunto de validación (upsampled):\")\n",
    "print(classification_report(target_valid, best_model_upsampled.predict(features_valid)))\n",
    "print(\"Mejores parámetros (upsampled):\", best_params_upsampled)\n",
    "print(\"Puntaje F1 en el conjunto de validación (upsampled):\", best_f1_upsampled)\n",
    "print(\"AUC-ROC en el conjunto de validación (upsampled):\", best_auc_roc_upsampled)\n",
    "\n",
    "# Imprimir el reporte de clasificación del mejor modelo en el conjunto de validación (downsampled)\n",
    "print(\"\\nReporte de clasificación en el conjunto de validación (downsampled):\")\n",
    "print(classification_report(target_valid, best_model_downsampled.predict(features_valid)))\n",
    "print(\"Mejores parámetros (downsampled):\", best_params_downsampled)\n",
    "print(\"Puntaje F1 en el conjunto de validación (downsampled):\", best_f1_downsampled)\n",
    "print(\"AUC-ROC en el conjunto de validación (downsampled):\", best_auc_roc_downsampled)\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de prueba (upsampled)\n",
    "target_pred_test_upsampled = best_model_upsampled.predict(features_test)\n",
    "\n",
    "# Imprimir el reporte de clasificación del mejor modelo en el conjunto de prueba (upsampled)\n",
    "print(\"\\nReporte de clasificación en el conjunto de prueba (upsampled):\")\n",
    "print(classification_report(target_test, target_pred_test_upsampled))\n",
    "print(\"Puntaje F1 en el conjunto de prueba (upsampled):\", f1_score(target_test, target_pred_test_upsampled))\n",
    "print(\"AUC-ROC en el conjunto de prueba (upsampled):\", roc_auc_score(target_test, best_model_upsampled.predict_proba(features_test)[:, 1]))\n",
    "\n",
    "# Evaluar el mejor modelo en el conjunto de prueba (downsampled)\n",
    "target_pred_test_downsampled = best_model_downsampled.predict(features_test)\n",
    "\n",
    "# Imprimir el reporte de clasificación del mejor modelo en el conjunto de prueba (downsampled)\n",
    "print(\"\\nReporte de clasificación en el conjunto de prueba (downsampled):\")\n",
    "print(classification_report(target_test, target_pred_test_downsampled))\n",
    "print(\"Puntaje F1 en el conjunto de prueba (downsampled):\", f1_score(target_test, target_pred_test_downsampled))\n",
    "print(\"AUC-ROC en el conjunto de prueba (downsampled):\", roc_auc_score(target_test, best_model_downsampled.predict_proba(features_test)[:, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero convierte las variables categóricas en variables dummy utilizando pd.get_dummies(), luego divide los datos en conjuntos de entrenamiento, validación y prueba. Luego, realiza un remuestreo de la clase minoritaria en el conjunto de entrenamiento para abordar el desequilibrio de clases. Después de entrenar varios modelos con diferentes hiperparámetros, selecciona el mejor modelo basado en el puntaje F1 en el conjunto de validación y evalúa su rendimiento en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones\n",
    "\n",
    "<p>El modelo parece ser efectivo para predecir si un cliente abandonará pronto el banco, con una capacidad F1 de prueba (downsampled) de 0.60, lo cuál es razonable para discriminar entre clientes que abandonan y no abandonan.\n",
    "\n",
    "Cuanto mayor sea el AUC-ROC, mejor será el rendimiento del clasificador en la clasificación binaria. Para ambos casos (upsampled y downsampled), el AUC-ROC en el conjunto de prueba es aproximadamente 0.85. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
